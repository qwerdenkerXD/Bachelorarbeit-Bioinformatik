\section{Material und Methoden} % (fold)
    \label{sec:material_und_methoden}
    % Erhalt numerischer Vektoren
    \subsection{Grundalgorithmus} % (fold)
        \label{sub:grundalgorithmus}
        \begin{algorithm}
            \caption{Vorbereitung}\label{alg:vorbereitung}
            \newcommand{\I}{\text{\textquotesingle}}
            \begin{algorithmic}
                \Require $sequence \in \{ \text{A-Z}, \I\Psi\I, \I\Omega\I, \I\Phi\I, \I\zeta\I, \I\Pi\I, \I\text{+}\I, \I\text{-}\I\}^{*} $
                \Require $0 \leq kf \leq 10$
                \Ensure $|aa\_vector| = |sequence|$
                \Ensure $v \geq 0\ \forall\ v \in aa\_vector$ 

                \State $aa\_vector \gets \texttt{array}()$
                \ForEach{$aa\ \textbf{in}\ sequence$}
                    \State $kf\_value \gets \texttt{get\_kf\_value}(aa, kf)$
                    \State $min\_kf\_value \gets \texttt{get\_min\_kf\_value}()$
                    \State $aa\_vector.\texttt{append}(kf\_value + \texttt{abs}(min\_kf\_value))$
                \EndFor
            \end{algorithmic}
        \end{algorithm}
        Voraussetzung für den Algorithmus ist ein numerischer Vektor, so wie es das Spektrum einer Tonspur bei SHAZAM darstellt. Um dies im Kontext von Proteinen zu erreichen, wird in \protfin\ auf sogenannte Kidera-Faktoren zurückgegriffen. Diese Faktoren stammen aus einem Forschungsprojekt von Akinori Kidera, welches 1985 publiziert wurde. Inhalt des Projekts war die statistische Faktorenanalyse von 188 physikalischen Eigenschaften der 20 natürlichen Aminosäuren zur Ermittlung von 10 dieser Eigenschaften, durch die die anderen aufgrund hoher Korrelation erklärt werden können \vgl{kidera}. In \autoref{tab:kidera} sind diese dargestellt.

        \begin{table}[h]
            \centering
            \caption{Kidera-Faktoren}
            \newcommand{\T}[1]{\centerIt{\textbf{#1}}}
            \label{tab:kidera}
            \csvreader[tabular=lllllllll,
              table head=\toprule\T{Beschreibung} & \T{A} & \T{C} & \T{D} & \T{E} & \T{F} & \T{G} & \textbf{\dots}\\\midrule,
              head to column names,
              late after line=\\,
              late after last line=\\\bottomrule
              ]%
              {../../prot-fin/materials/Amino_Acid_Kidera_Factors.csv}{Kidera_Factor=\KF, Kidera_Factor_Description=\KFD}%
            {\KFD & \A  & \C & \D & \E & \F & \G & \dots}
        \end{table}

        \newpage
        Folglich kann eine Aminosäuresequenz pro Faktor in einen numerischen Vektor übersetzt werden, wobei ein höherer absoluter Wert für mehr Relevanz des Faktors steht. Hätte man also die Beispielsequenz \texttt{EVKEFDGQGCFC}, wäre die Übersetzung für die Hydrophobizität die folgende:

        \begin{table}[h]
            \centering
            \begin{tabular}{cccccccccccc}
                % x=list(np.random.choice(list("ACDEFGHIKLMNPQRSTVWY"), len("cccccccccccc"), p=[.1,.1,.1,.1,.1,.1,*([.4/14]*14)]));" & ".join(x);" & ".join(str(KIDERA_TABLE[i][3]) for i in x)
                E & V & K & E & F & D & G & Q & G & C & F & C\\
                1.17 & -0.4 & 1.7 & 1.17 & -1.43 & 0.81 & -0.16 & 1.1 & -0.16 & -1.05 & -1.43 & -1.05
            \end{tabular}
        \end{table}

        Da für die Fourier Transformation negative Werte problematisch sind, wird der Vektor anschließend dahingehend normalisiert, dass das absolute Minimum aller Werte aus \autoref{tab:kidera} aufaddiert wird. Das absolute Minimum ist 2.33, weshalb der normalisierte Ergebnisvektor der Beispielsequenz nun so aussieht:
        \begin{equation}
            \newcommand{\sminus}{\scalebox{0.8}[1]{-}}
            \label{equ:normalization}
            \begin{split}
                raw\_vec & = [1.17\ \sminus0.4\ \ 1.7\ \ 1.17\ \sminus1.43\ \ 0.81\ \sminus0.16\ \ 1.1\ \sminus0.16\ \sminus1.05\ \sminus1.43\ \sminus1.05]\\
                normalized\_vec & = raw\_vec + 2.33\\
                normalized\_vec & = [3.5\ \ 1.93\ \ 4.03\ \ 3.5\ \ 0.9\ \ 3.14\ \ 2.17\ \ 3.43\ \ 2.17\ \ 1.28\ \ 0.9\ \ 1.28]
            \end{split}
        \end{equation}

        % Sammeln struktureller Information
        % \vspace{2.25mm}
        \begin{algorithm}
            \caption{Sammeln von Strukturdaten}\label{alg:strukturdaten}
            \begin{algorithmic}
                \Require $v \geq 0\ \forall\ v \in aa\_vector$ 
                \Ensure $constellation\_map$ is an Array of Arrays of Floats

                \State $constellation\_map \gets \texttt{array}()$
                \State $stft\_result \gets \texttt{stft\_transform}(aa\_vector)$
                \ForEach{$window\ \textbf{in}\ stft\_result$}
                    \State $selected\_frequencies \gets \texttt{select\_maxima}(window)$
                    \State $constellation\_map.\texttt{append}(selected\_frequencies)$
                \EndFor
            \end{algorithmic}
        \end{algorithm}
        Der erhaltene Vektor aus \autoref{alg:vorbereitung} wird nun strukturell analysiert. Dieses Vorgehen basiert auf der Short-Time-Fourier-Transformation (STFT), welche den Vektor fensterweise auf periodische Signale untersucht, wie z.B. dem wiederholten Auftreten von hydrophoben Aminosäuren im gleichen Abstand oder in der Musik ein Refrain oder dem Rhythmus. Für jedes Fenster werden die Frequenzen der auffälligsten Signale ausgewählt, wie in \autoref{fig:freq_selection} dargestellt mittels der lokalen Maxima, sodass über alle Intervalle eine sogenannte Constellation-Map entsteht. Diese Map wird dabei als Array repräsentiert, wobei jedes Element hierbei eine Liste darstellt, die ihrem Index entsprechend die gewählten Frequenzen des jeweiligen Fensters beinhaltet. In \autoref{fig:hashing} ist im linken Teil die visuelle Darstellung einer Constellation-Map als Scatter-Plot abgebildet.

        \newpage
        % Hashing
        % \vspace{2.25mm}
        \begin{algorithm}
            \caption{Hashing}\label{alg:strukturdaten}
            \begin{algorithmic}
                \Require $constellation\_map$ is an Array of Arrays of Floats
                \Require $protein\_id$ is a String
                \Require $0 \leq kf \leq 10$
                \Ensure $hashes$ is a HashMap of $Int \rightarrow Int, String$

                \State $hashes \gets \texttt{hashmap}()$
                \State $window\_idx \gets 0$
                \Repeat
                    \State $selected\_frequencies \gets constellation\_map.\texttt{pop}(0)$
                    \ForEach{$frequency\ \textbf{in}\ selected\_frequencies$}
                        \State $successor\_idx \gets 0$
                        \ForEach{$succ\_frequencies\ \textbf{in}\ constellation\_map$}
                            \ForEach{$succ\_frequency\ \textbf{in}\ succ\_frequencies$}
                                \State $hash \gets \texttt{create\_hash}(frequency, succ\_frequency, successor\_idx, kf)$
                                \State $hashes[hash] \gets (window\_idx, protein\_id)$
                            \EndFor
                        \EndFor
                        \State $successor\_idx \gets successor\_idx + 1$
                    \EndFor
                    \State $window\_idx \gets window\_idx + 1$
                \Until{$constellation\_map$ is empty}
            \end{algorithmic}
        \end{algorithm}

        \begin{figure}[H]
            \centering
            \includegraphics[width=1\textwidth]{plot_method.png}
            \caption{Constellation-Map und Hashing: Die Punkte bilden die Constellation-Map. Die zur Übersicht nur rechts eingezeichneten Kanten repräsentieren die Hash-Bildung, wobei rote Kanten ignorierte Hashes darstellen, weil sie mehrfach auftauchen.}
            \label{fig:hashing}
        \end{figure}

        Die erhaltene Map wird nun elementweise gehashed, um einen effizienten Vergleich mit anderen Maps zu ermöglichen. Um das zu erzielen wird jede ausgewählte Frequenz eines Fensters mit jeder weiteren Frequenz der Nachfolgefenster gepaart. Bildlich gesprochen werden also Kanten gebildet, wodurch die Map zu einem Graphen wird. Jede dieser Kanten bildet nun einen Hash, also einer Kombination aus den beiden Frequenzen/Kantenenden und der Kantenlänge (hier $\texttt{successor\_idx}$, beginnend mit 0). In einer Hashmap wird sich folgend für den Hash die Position der Kante in der Constellation-Map gemerkt, sowie die ID des Proteins, für die diese Map erstellt wurde. Sollte ein Hash dabei mehrfach vorkommen, verbleibt lediglich seine letzte Position. Dieses Verfahren wird im rechten Teil von \autoref{fig:hashing} repräsentativ dargestellt, wobei rote Linien die ignorierten Kanten abbilden.

        % hierzu ein Plot zur Veranschaulichung der Offsets
        % Scoring/Map-Vergleich
        \vspace{2.25mm}
        \textbf{Single-Protein-Matching:}\ \ Nachdem eine Datenbank mit den Hashes verschiedener Trainings-Proteine (TP) trainiert wurde, wird sie verwendet, um Proteine zu erkennen. Dazu werden für die jeweilige Eingabesequenz von Aminosäuren die Hashes gebildet und deren Positionen gespeichert. Um nun die Ähnlichkeit der Constellation-Map der Eingabe mit denen der TP zu bestimmen, werden pro Eingabe-Hash die Differenzen zwischen dessen Position mit den Positionen der trainierten Hashes gebildet und global pro Protein gezählt. Diese Differenzen repräsentieren den Abstand der Kante in der Eingabe-Map zur Kante der jeweiligen TP-Map, also wie weit die Eingabe-Map verschoben wäre, sollte es sich bei dem TP um das Original handeln. Auf diese Weise sammeln sich pro TP mehrere solcher potentiellen Abstände, wobei nun der Abstand, der am häufigsten aufgetreten ist, offensichtlich die meiste Übereinstimmung in den Kanten zeigt. Diese Tatsache qualifiziert diese Maximalanzahl als geeigneten Score (S1) für ein Match.

        Da es große Proteine mit sehr langen Aminosäuresequenzen kürzere Sequenzen kleinerer funktionsungleicher Proteine enthalten können, reicht der ermittelte Score alleine nicht aus, da in diesem Fall sehr viele Kanten der Eingabe-Map übereinstimmen würden, sodass trotz Mis-Match der nahezu maximale Score erreicht werden würde.

        Um das zu umgehen, wird der Jaccard-Similarity-Index (JSI) verwendet, einem Maß, das die Übereinstimmung zweier Mengen A und B wie folgt bewertet:
        $$JSI(A, B)=\frac{|A \cap B|}{|A \cup B|}$$
        Dieser Index nimmt einen Wert von 0 an, wenn beide Mengen disjunkt sind, und nähert sich der 1 je größer die Schnittmenge ist. Im Fall des Vergleichs zweier Constellation-Maps, also zwei Hash-Mengen, wird hier bewertet, wie viele Kanten sich die beiden Maps positionsunabhängig teilen. Durch diese Unabhängigkeit reicht der JSI alleine nicht als Score aus, sodass nur in Kombination/Multiplikation mit dem S1 ein robuster Score entsteht, da beide zusammen ihre Schwächen aufheben.

        \vspace{2.25mm}
        \textbf{Family-Matching:}\ \ Wenn \protfin\ wie erwartet funktioniert, sollten beim Single-Protein-Matching die Matches mit den besten Scores funktionsähnliche Proteine sein. Ein weiterer Ansatz, solche Verwandten zu ermitteln, ist das Matching mit Proteinfamilien. Hierbei wird als Eingabe eine Tabelle akzeptiert, die lediglich eine Zuordnung von Protein-ID und Familie enthält. Um nun Matches zu finden, werden von allen Hashes einer Familie nur die behalten, die in allen Mitgliedern vorkommen. Anschließend wird die Datenbank nach Proteinen durchsucht, welche ebenfalls diese Hashes enthalten, wobei als Score diesmal nur die Anzahl infrage kommt, wie viele der Hashes enthalten sind. Die Idee hinter dieser Methode ist, dass Proteine derselben Proteinfamilie, also mit ähnlichen Funktionen, möglicherweise familienspezifische Kanten in der Constellation-Map haben.
    % subsection grundalgorithmus (end)
    \subsection{Experiment 1: UniRef90 Sampling} % (fold)
        \label{sub:experiment_1_uniref90_sampling}
        Ein wichtiger Bestandteil des \hyperref[sec:grundalgorithmus]{Algorithmus} ist die Selektion signifikanter Frequenzen zur Erstellung der Constellation-Map. Es wäre möglich, einfach alle Frequenzen auszuwählen und die Signalstärke in den Hash einfließen zu lassen. Problem hierbei ist aber, dass diese Vorgehensweise zu wesentlich mehr Hashes und einer folglich sehr großen Datenbank führt, was wiederum das Scoring/Matching verlangsamt. Ein Anspruch an \protfin\ ist, dass die Datenbankgröße die Eingabegröße nicht wesentlich übersteigt, wobei es sich bei der Eingabe um eine einfache FASTA-Datei handelt.

        Diesem Problem soll durch ein Sampling-Experiment abgeholfen werden. Darin werden aus etwa 180 Millionen Sequenzen je ein zufälliges Intervall für die STFT ausgewählt, transformiert und die Signalstärken je Frequenz gemerkt. Um nun daraus eine Selektionsmethode abzuleiten, werden die Grenzquantile einer jeden Frequenz ermittelt, um signifikant seltene Signalstärken zu ermitteln. Folglich ist es möglich, für die Constellation-Map nur diejenigen Frequenzen zu behalten, welche in den Randzonen der Signalstärken liegen, sodass nicht nur Signale infrage kommen, die für eine besonders starke Ausprägung eines Kidera-Faktors sprechen, sondern auch für den Fall der umgekehrten Ausprägung, wie z.B. Hydrophilie statt Hydrophobie.

        Der Algorithmus wird daher insofern angepasst, dass bei der Frequenz-Selektion von den Maxima der Signalstärken nur die behalten werden, die die Grenzwerte über-/unterschreiten. Zudem wird beim Hashing je Frequenz noch die Information hinzugefügt, ob sie besonders stark oder schwach ist.
    
    % subsection experiment_1_uniref90_sampling (end)
% section material_und_methoden (end)
