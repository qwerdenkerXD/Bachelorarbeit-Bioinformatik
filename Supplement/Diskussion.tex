\section{Diskussion} % (fold)
    \label{sec:diskussion}
    Die Entwicklung von \protfin\ hat das Ziel, eine mögliche Alternative zu Alignment-basierten Verwandtschaftsanalysen zwischen Proteinen zu erhalten. Der zugundeliegende Algorithmus ist dabei von SHAZAM inspiriert, welches Musik erkennt, indem es Tonaufnahmen nicht auf direkte Ähnlichkeit vergleicht, wie es bei einem Alignment der Fall wäre, sondern durch Vergleich der periodischen Signale innerhalb der Aufnahmen. Dies wurde nun halbwegs erfolgreich bei \protfin\ umgesetzt. Halbwegs deswegen, weil die Erkennung von Proteinen zwar funktioniert, dafür aber die Performanz hinsichtlich Speicherbedarf der Datenbanken und daraus resultierenden hohen Laufzeiten nicht gut ist. Außerdem fehlt eine robuste und zuverlässige Möglichkeit, verwandte Proteine zu identifizieren. Um diesen Mangeln entgegenzuwirken, wurden \theexperiment\ verschiedene Experimente entwickelt, die zum Ziel haben, nur möglichst signifikante Signale in die Datenbank einfließen zu lassen.

    Verglichen mit den Ergebnissen der vorigen Version von \protfin\ in \autoref{fig:prev_results}, wurde in allen angesetzten Experimenten eine Verbesserung in den Datenbankgrößen erzielt, abgesehen von \acf{FG} 10, welche an Eindeutigkeit der Ergebnisse verloren hat. Es ist hier aber wichtig zu bemerken, dass in der Vorversion das Matching lediglich für nur einen \acf{KF} durchgeführt wurde. Daher ergibt der Verlust bei \ac{FG} 10 Sinn, da die so wenigen infrage kommenden Frequenzen trotzdem auf über 100 \acs{MB} aufgebläht wurden. Bezüglich der Schärfe lässt sich hier leider kein Vergleich vornehmen, da dieses Maß in der Vorversion noch nicht implementiert war. Ebenso stammt der Ansatz des Family-Matchings auch erst aus dieser Arbeit.

    Das Sampling scheint eine gute Idee gewesen zu sein, um die Frequenzselektion signifikanter zu gestalten, ohne dabei willkürlich Information zu entfernen. In \autoref{fig:frequencies_uniref} ist der Effekt auf die Wahl deutlich zu erkennen. Interessant hierbei ist, dass es für mehrere Signifikanzniveaus in jeder 10. Aminosäure ein periodisches Signal gibt. Das betrifft bei einem Fenster der Größe 30 zwar nur drei und ist vielleicht in den \acf{TP} begründet, aber könnte möglicherweise auf ein konzeptuelles Problem hindeuten. Für zukünftige Ergebnisse sollte das im Hinterkopf behalten werden.

    Bezüglich der Werte für $\alpha \le 0.01\%$ ist es zweifelhaft, ob bei diesen niedrigen Häufigkeiten unter 100 wirklich alle \ac{TP} abgedeckt werden können. Für $\alpha=5\%$ sieht das Matching in \autoref{fig:uniref90.sp} jedenfalls noch in Ordnung aus. Da die Datenbankgrößen dennoch recht hoch sind, wäre hier nur eine Reduktion über andere Ansätze denkbar, wie zum Beispiel das Filtern von Hashes in \autoref{exp:filter_hashes}. Die Ergebnisse dort zeigen, dass auf diese Weise effektiv kleinere Datenbanken erzielt werden, wobei die Schärfe und Identifikationsrate scheinbar verlustfrei bleiben. Da bei dem Experiment zudem die gelernten Grenzwerte das alleinige Selektionskriterium darstellen, im Gegensatz zur Kombination mit Wahl lokaler Maxima wie bei \autoref{exp:uniref90}, sollte dies für die Ergebnisse in \autoref{fig:uniref90.sp} zu einer Verbesserung führen. \autoref{fig:filter_hashes.fam} betrachtend, scheint wohl ein zu behaltendes Quantil der Hashes von $10\%$ geeignet zu sein. Allerdings ist der steigende F-Score mit kleiner werdendem Quantil dadurch zu erklären, dass die Wahrscheinlichkeit auf falsche Treffer sinkt, wenn weniger Hashes behalten werden. Die Mitglieder der Familie sind auf jeden Fall enthalten, sofern es Hashes gibt, die sie sich teilen. Die Auswertung der Ergebnisse des Family-Matchings sollte dahingehend erweitert werden, dass angegeben wird, wie viele Familien keine Hashes hatten und was darin die jeweilige Mindestzahl an Hashes ist, die ein Mitglied hat, damit die Darstellung der Ergebnisse weniger irreführend gestaltet werden kann. Ebenso ist es denkbar, dass das Verhältnis von mittlerer Hashanzahl in der Familie und der tatsächlichen Menge geteilter Hashes als Bewertungsmaß neben dem F-Score einfließt.

    In \autoref{exp:target_zone} wird dieselbe Selektionsmethode wie in \autoref{exp:uniref90} verwendet. Es zeigt sich, dass eine \acf{TZ} von 8, also einem Bedarf von 3 Bit, vollkommen ausreichend für die Identifikation ist, welche in ihrer Bewertung keine Einbußen hat und eine Datenbankgröße von medialen etwa 100 \acs{MB} zur Folge hat.

    Bei \autoref{exp:selection_method} hat sich offenbar nur eine Methode als tauglich erwiesen, nämlich die Frequenzen danach zu wählen, wie stark deren Amplituden von den gelernten Grenzwerten in \autoref{exp:uniref90} abweichen. Die Datenbankgrößen sind sehr gut, wenn man bedenkt, dass hier keine Hashes herausgefiltert wurden, sondern das lediglich über diese Selektion mit \ac{TZ} 8 erzielt wurde. Der Parameter $k=3$ scheint ganz geeignet zu sein, die Werte beim Single-Protein-Matching sind da am besten. Beim Family-Matching beeinflusst $k$ scheinbar nicht allzu viel, wenn die Ergebnisse nicht irreführend sind, nur bei \ac{FG} 50 gibt es offenbar einen erhöhten F-Score. Für die weitere Entwicklung sollte diese Selektionsmethode auf jeden Fall in Betracht gezogen werden. Bei Durchführungen, die weiterhin $k$-Werte austesten, reicht es, nur ein $k \in \{0, 1\}$ zu testen, da die Ergebnisse immer identisch sind. Dies liegt daran, dass die Frequenzen nach lokalen Maxima ausgewählt werden, was bedeutet, dass die Randfrequenzen niemals infrage kommen können, da ihr Extremverhalten nur von einer Seite betrachtet werden kann. Wenn also $k=1$ gilt, wird eine Frequenz ignoriert, die sowieso niemals gewählt wird.

    Was in den Ergebnissen fehlt, ist beim Single-Protein-Matching der Bezug zur Familienähnlichkeit. Aktuell wird lediglich betrachtet, ob das Protein selbst identifiziert wurde und wie weit sich der Score von den Treffern abhebt, die nicht in der Familie sind. Letzteres wird durch die Schärfe abgebildet, die den Abstand prozentual angibt, also wie viel höher der Score ist. Dieser Abstand soll möglichst hoch sein, der zu den Familienmitgliedern hingegen nicht. Die Schärfe müsste um diese Information erweitert werden, was sich folgendermaßen formulieren lässt:
    \begin{equation}
        \label{equ:}
        \begin{split}
            scores\_trp &= \{\emph{S1}(t) \cdot JSI(t) \mid t \in TrP\}\\
            scores\_fp &= \{\emph{S1}(f) \cdot JSI(f) \mid f \in FP\}\\
            dist\_nicht\_familie &= \frac{\texttt{max}(scores\_trp) - \texttt{max}(scores\_fp)}{\texttt{max}(scores\_trp)}\\
            dist\_familie &= \frac{\texttt{max}(scores\_trp) - \texttt{mean}(scores\_trp \setminus \{\texttt{max}(scores\_trp)\})}{\texttt{max}(scores\_trp)}\\
            \emph{Schärfe} &= dist\_nicht\_familie * (1 - dist\_familie)
        \end{split}
    \end{equation}

    $TrP$ sind die Treffer innerhalb der Familie und $FP$ die anderen. Der Abstand ($dist$) zu den $TrP$ ist, wie sehr sich der beste Score der Familie prozentual von allen anderen Familienmitgliedern abhebt. Damit dieser Abstand in die Schärfe minimierend einfließt, wird diese wie bisher berechnet und anschließend mit der Umkehrung des Familienabstands multipliziert, also wie nah der beste Score den $TrP$ ist. Auf diese Weise wäre ein hoher Abstand zu $FP$ bei ebenso hohem Abstand zu $TrP$ trotzdem schlecht bewertet. Gleiches gilt umgekehrt, dass eine hohe Nähe zu den Familienmitgliedern auch schlecht bewertet wird, wenn die $FP$ ebenso nah sind. Gegebenenfalls sollte der Abstand zu den $FP$ auch über den Mittelwert berechnet werden anstelle des Maximums, damit die Schärfe robuster gegenüber Ausreißern der $FP$ ist.

    \subsection*{Ausblick} % (fold)
        \label{sub:ausblick}
        \dots
    
    % subsection ausblick (end)
% section diskussion (end)