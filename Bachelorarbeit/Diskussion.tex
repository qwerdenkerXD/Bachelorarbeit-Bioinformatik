\section{Diskussion} % (fold)
    \label{sec:diskussion}
    Die Entwicklung von \protfin\ hat das Ziel, eine mögliche Alternative zu Alignment-basierten Verwandtschaftsanalysen zwischen Proteinen zu erhalten. Der zugundeliegende Algorithmus ist dabei von SHAZAM inspiriert, welches Musik erkennt, indem es Tonaufnahmen nicht auf direkte Ähnlichkeit vergleicht, wie es bei einem Alignment der Fall wäre, sondern durch Vergleich der periodischen Signale innerhalb der Aufnahmen. Dies wurde zum Teil erfolgreich bei \protfin\ umgesetzt, denn die Erkennung von Proteinen funktioniert zwar, dafür ist aber die Performanz hinsichtlich Speicherbedarf der Datenbanken und daraus resultierenden hohen Laufzeiten nicht gut. Außerdem fehlt bisher eine robuste und zuverlässige Möglichkeit, verwandte Proteine zu identifizieren. Um diesen Mangeln entgegenzuwirken, wurden \NumWord{\theexperiment} verschiedene Experimente entwickelt, die zum Ziel haben, nur möglichst signifikante Signale in die Datenbank einfließen zu lassen.

    Verglichen mit den Ergebnissen der vorigen Version von \protfin\ in \MyRef{fig:prev_results}, wurde in allen angesetzten Experimenten eine Verbesserung in den Datenbankgrößen erzielt, abgesehen von \acf{FG} 10, welche an Eindeutigkeit der Ergebnisse verloren hat. Es ist hier aber wichtig zu bemerken, dass in der Vorversion das Matching lediglich für nur einen \acf{KF} durchgeführt wurde. Daher ergibt der Verlust bei \ac{FG} 10 Sinn, da die so wenigen infrage kommenden Frequenzen trotzdem auf über 100 \acs{MB} aufgebläht wurden. Bezüglich der Schärfe lässt sich hier leider kein Vergleich vornehmen, da dieses Maß in der Vorversion noch nicht implementiert war. Ebenso stammt der Ansatz des Family-Matchings auch erst aus dieser Arbeit.

    Das Sampling scheint eine gute Idee gewesen zu sein, um die Frequenzselektion signifikanter zu gestalten, ohne dabei willkürlich Information zu entfernen. In \MyRef{fig:frequencies_uniref} ist der Effekt auf die Wahl deutlich zu erkennen. Die Reduktion der Häufigkeit, mit der eine Frequenz gewählt wird, im Vergleich zu den vorigen Ergebnissen bei nur einem betrachteten \ac{KF} ist hier sehr stark erfolgt. So liegt der Maximalwert bei $\alpha=5\%$ und allen \acp{KF} bei etwa 45000 (\MyRef{fig:frequencies_5}) und in der Vorversion mit nur einem \ac{KF} bei fast dem Zehnfachen (\MyRef{fig:frequencies_normal}). Dennoch ähneln sich beide Varianten in der Hinsicht, dass Frequenz 0.1 am häufigsten auftaucht, also einer Periode von jeder 10. Aminosäure (Reziproke der Frequenz ist Periodenweite).

    Die geringere Anzahl Frequenzen zeigt sich in \MyRef{fig:uniref90.sp} in deutlich kleineren Datenbankgrößen als vorher (\MyRef{fig:prev_results}).

    Bezüglich der Werte für $\alpha \le 0.1\%$ ist es zweifelhaft, ob bei diesen niedrigen Häufigkeiten unter 200 wirklich alle \acf{TP} abgedeckt werden können, zumindest mit dem in \Exp{exp:uniref90} verwendeten Selektionsansatz. Für $\alpha=5\%$ ist das Single-Protein-Matching in \MyRef{fig:uniref90.sp} jedenfalls noch vielversprechend.

    Da die Datenbankgrößen dennoch recht hoch sind, wäre hier nur eine Reduktion über andere Ansätze denkbar, wie zum Beispiel das Filtern von Hashes in \MyRef{exp:filter_hashes}. Die Ergebnisse dort zeigen, dass auf diese Weise effektiv kleinere Datenbanken erzielt werden, wobei die Schärfe und Identifikationsrate verlustfrei bleiben. Da bei dem Experiment zudem die gelernten Grenzwerte das alleinige Selektionskriterium darstellen, im Gegensatz zur Kombination mit Wahl lokaler Maxima wie bei \MyRef{exp:uniref90}, sollte dies für die Ergebnisse in \MyRef{fig:uniref90.sp} zu einer Verbesserung führen.

    Das Single-Protein-Matching bei \Exp{exp:filter_hashes} hat gute Ergebnisse hervorgebracht. In \MyRef{fig:filter_hashes.sp} ist klar zu erkennen, wie das Filterquantil lediglich die Datenbankgröße beeinflusst. Es hat sich somit durch die kleinen Datenbanken bei kleinem Quantil gezeigt, dass die Hashes, die in sehr vielen Proteinen vorkommen, wenig Relevanz für das Single-Protein-Matching haben.

    Auch beim Family-Matching stechen die kleinen Quantile hervor. Das in \MyRef{fig:filter_hashes.fam} kleinste Quantil der Hashes von $10\%$ hat hier den besten Score. Allerdings ist der steigende F-Score mit kleiner werdendem Quantil dadurch zu erklären, dass die Wahrscheinlichkeit auf falsche Treffer sinkt, wenn weniger Hashes behalten werden. Die Mitglieder der Familie sind schließlich garantiert enthalten, sofern es Hashes gibt, die sie sich teilen.

    In \MyRef{exp:target_zone} wird dieselbe Selektionsmethode wie in \MyRef{exp:uniref90} verwendet. Es zeigt sich, dass eine \acf{TZ} von 8, also einem Bedarf von 3 Bit, vollkommen ausreichend für die Identifikation ist. Wie auch in den Ergebnissen zu \Exp{exp:filter_hashes} in \MyRef{sub:filter_results} ist hier beim Single-Protein-Matching kein Verlust an Präzision bei der Erkennung von Proteinen sichtbar (siehe \MyRef{fig:target_zone.sp}). Insofern scheint die \ac{TZ} von 8 die beste Wahl zu sein, um eine kleine Datenbank zu erzielen. Lediglich \ac{FG} 10 hat eine schlechte Performanz, doch das hängt mit dem verwendeten Signifikanzniveau von 5\% zusammen, welches schon in dem repräsentativen Single-Protein-Matching in \MyRef{sub:uniref90} von \Exp{exp:uniref90} eine schlechte Identifikation lieferte.

    \dots Selection-Method \dots

    Was in den Ergebnissen fehlt, ist beim Single-Protein-Matching der Bezug zur Familienähnlichkeit. Aktuell wird lediglich betrachtet, ob das Protein selbst identifiziert wurde und wie weit sich der Score von den Treffern abhebt, die nicht in der Familie sind. Letzteres wird durch die Schärfe abgebildet, die den Abstand prozentual angibt, also wie viel höher der Score ist. Dieser Abstand soll möglichst hoch sein, der zu den Familienmitgliedern hingegen nicht. Die Schärfe müsste um diese Information erweitert werden, was sich folgendermaßen formulieren lässt:
    \begin{equation}
        \label{equ:}
        \begin{split}
            scores\_trp &= \{\emph{S1}(t) \cdot JSI(t) \mid t \in TrP\}\\
            scores\_fp &= \{\emph{S1}(f) \cdot JSI(f) \mid f \in FP\}\\
            dist\_nicht\_familie &= \frac{\texttt{max}(scores\_trp) - \texttt{max}(scores\_fp)}{\texttt{max}(scores\_trp)}\\
            dist\_familie &= \frac{\texttt{max}(scores\_trp) - \texttt{mean}(scores\_trp \setminus \{\texttt{max}(scores\_trp)\})}{\texttt{max}(scores\_trp)}\\
            \emph{Schärfe} &= dist\_nicht\_familie \cdot (1 - dist\_familie)
        \end{split}
    \end{equation}

    $TrP$ sind die Treffer innerhalb der Familie und $FP$ die anderen. Der Abstand ($dist$) zu den $TrP$ ist, wie sehr sich der beste Score der Familie prozentual von allen anderen Familienmitgliedern abhebt. Damit dieser Abstand in die Schärfe minimierend einfließt, wird diese wie bisher berechnet und anschließend mit der Umkehrung des Familienabstands multipliziert, also wie nah der beste Score den $TrP$ ist. Auf diese Weise wäre ein hoher Abstand zu $FP$ bei ebenso hohem Abstand zu $TrP$ trotzdem schlecht bewertet. Gleiches gilt umgekehrt, dass eine hohe Nähe zu den Familienmitgliedern auch schlecht bewertet wird, wenn die $FP$ ebenso nah sind. Gegebenenfalls sollte der Abstand zu den $FP$ auch über den Mittelwert berechnet werden anstelle des Maximums, damit die Schärfe robuster gegenüber Ausreißern der $FP$ ist.

    \subsection*{Ausblick} % (fold)
        \label{sub:ausblick}
        SHAZAM ist zweifellos sehr erfolgreich in der Erkennung von Musik mittels Tonaufnahmen, die aufgrund schlechter Mikrofonqualität sehr verzerrt sind. Durch das Aufteilen in mehrere Fenster, die einen Umfang von unter einer Sekunde haben, wird dies ermöglicht, da somit nicht relevant ist, wo die Aufnahme startet.

        Wie in der Einleitung (\autopageref{sec:einleitung}) erwähnt, sind Vektoren der digitalen Musik deutlich länger als Proteinsequenzen. Ein Fenster von einer halben Sekunde hätte etwa 20000 Werte. Bei einem angenommenen Originalsong von drei Minuten Länge (180 Sekunden) und 50\% Überlappung der Fenster wären das $\frac{180 * (20000 * 2)}{0.5 * 20000}=720$ Fenster.

        Die Umsetzung dieses Verfahrens auf Proteine führt aktuell in \protfin\ allerdings zu Fenstern von maximal Länge 50 (siehe \MyRef{tab:parameter}), was bei einer medialen Aminosäuresequenzlänge von 300 (\MyRef{fig:sequences}) bei auch 50\% Überlappung zu lediglich $\frac{300}{0.5 * 50}=12$ Fenstern führt.

        Die kurzen Fenster führen zu einer geringen Anzahl überhaupt möglicher Frequenzen und die wenigen Fenster zu eingeschränkter Hashbildung. Es ist nicht auszuschließen, dass dieser aktuelle Ansatz der Übersetzung einer Aminosäuresequenz in einen numerischen Vektor nicht zielführend ist.

        Sollten weitere Experimente weiterhin eine schlechte Performanz hinsichtlich der Erkennung funktional Verwandter aufweisen, gibt es noch alternative Ansätze, den numerischen Vektor zu generieren:
        \begin{enumerate}
            \item Ein noch nicht weiterverfolgter Weg ist, die Sequenzen in echte Musik zu übersetzen, sodass SHAZAM direkt darauf angewandt werden könnte. \Anhang{A0A1D8EJF9.wav} ist eine Beispielmusikdatei, die in einem anfänglichen Test aus einer Aminosäuresequenz generiert wurde, wobei jede Aminosäure in einem Akkord aus \acp{KF} entsprach.

            Ein solcher Akkord besteht folglich aus 10 Tönen, dessen Lautstärke durch den jeweiligen Wert eines \ac{KF} beeinflusst wird (näheres dazu siehe \Anhang{README.txt} im Abschnitt \texttt{Reproduzierbarkeit} zu \texttt{A0A1D8EJF9.wav}). Problem hierbei war ebenso die Datenbankgröße, da Musik komplexer als Text ist. Dennoch ist der Kern der Idee vielleicht trotzdem richtig, da die Aminosäuresequenz so den Umfang von tausenden Werten hätte, wie auch Musik, und SHAZAM direkt auf diese synthetische Aufnahme angewandt werden könnte. Die exakte Methode, wie die Übersetzung am besten erfolgt, müsste dann ausgetestet werden.

            \item Ebenso möglich wäre, anstelle ein synthetische Musik zu generieren, stattdessen den aktuell erstellten Vektor, wie in \MyRef{fig:normalization} dargestellt, durch lineare Interpolation um weitere Werte zu ergänzen. Auf diese Weise wären ebenfalls mehr Fenster möglich, abhängig davon, um wie viele Werte der Vektor erweitert wird.
        \end{enumerate}
        
        Es gibt allerdings auch noch Wege, wie die aktuelle Implementierung weiterentwickelt werden kann. So ist zum Beispiel das Family-Matching ausbaufähig. Neben den oben genannten Änderungen, könnte ebenfalls die Bewertungsmethode der Treffer erweitert werden. Aktuell ist deren Score lediglich die Anzahl Hashes, die mit den Hashes der Familie übereinstimmen, wie auf \autopageref{fam.matching} erläutert. Im Gegensatz zum Single-Protein-Matching wird hier die Position der Hashes also nicht einbezogen, was die Wahrscheinlichkeit auf Übereinstimmung deutlich erhöht. Der Grund ist, dass nicht klar ist, ob die Hashes auch innerhalb der Familie dieselben Positionen haben. Das müsste experimentell ermittelt werden. Andernfalls wäre es auch ein möglicher Ansatz, alle Positionen P zu speichern und bei der Identifizierung eines Treffers einen Hash nur als Übereinstimmung zu bewerten, wenn seine Position Teil von P ist.

        Das Speichern aller Positionen der Hashes wäre ebenso eine Option für das Single-Protein-Matching. Zwar würde das Ermitteln des S1-Score, siehe \MyRef{fig:scoring}, deutlich aufwändiger sein, aber möglicherweise wäre dieser Score dann gar nicht mehr notwendig. Wenn bei der Generierung der Hashes in \MyRef{alg:hashing} nicht die Position selbst, sondern die Anzahl der Positionen gespeichert werden würde, wäre die Summe der Werte der Hashes die Gesamtzahl an Hashes des Proteins. Werden die Hashes zweier Proteine verglichen, so bildet die Summe der absoluten Differenzen der geteilten Hashes die Übereinstimmung beider Proteine.

        Das Verhältnis beider wäre konzeptuell dem \ac{JSI} ähnlich, nur dass die beiden Mengen Duplikate enthalten dürfen. Das Problem, dass der \ac{JSI} positionsunspezifisch ist, wird hier dadurch ausgeglichen, dass wirklich alle Hashes in den Score einfließen. Denn die Kombination aller Hashes beinhaltet deren Positionen in abstrakter Form, da die Hashes prinzipiell Kanten in einem fast vollständigen Graph sind, wie in \MyRef{fig:hashing} dargestellt. Hat man eine Kante, folgt zwangsläufig daraus, dass von den Enden ebenfalls weitere Kanten ausgehen, und mit der Vorgabe, nach welchem System die Punkte verbunden werden, entsteht trotzdem der ursprüngliche Graph. Demzufolge wäre es auch möglich, mit diesem Score die \ac{TZ} wieder zu erweitern, um einen vollständigeren Graph aus der \acf{CM} zu erstellen, wobei die Performanz des Scorings davon unberührt bliebe.

        Ein Problem, das bei den kleinen \acp{FG} angegangen werden muss, ist die Hashbildung. Bei einer maximalen \ac{FG} von 50 gibt es 26 Frequenzen, die als Minimum oder Maximum ausgewählt werden können. Bei einer \ac{TZ} von 8 sind das ${(26 \cdot 2)}^{2} \cdot 8 = 21632$ mögliche Kombinationen, die ein Hash annehmen kann. Davon ausgehend, dass \protfin\ mit öffentlichen Datenbanken wie der UniProtKB \autocite{uniprot} werden soll, welche in Version \texttt{2024\_04} vom 24.07.2024 über 200 Millionen von Einträgen in TrEMBL hat und über 500 Tausend in Swiss-Prot, ist das viel zu unspezifisch.

        Sollte es bei diesen kleinen Fenstern bleiben, muss der Informationsgehalt \autocite{shannon} eines Hashes deutlich erhöht werden. Hierfür könnten zum Beispiel statt Paaren von Punkten der \ac{CM} größere n-Tupel kombiniert werden, wobei hier die Gefahr zu hoher Spezifität besteht. Dennoch würde die Anzahl möglicher Kombinationen in Abhängigkeit von $n$ exponentiell steigen ($(26 \cdot 2)^{n}\cdot 8$) und entspräche zum Beispiel für Quadrupel schon 7311616, was deutlich mehr ist. Das oben beschriebene Einbeziehen aller Hash-Positionen wäre vielleicht auch eine Option für das Problem oder die Erweiterung der Vektoren, weil Ersteres die Häufigkeit eines Hashes einbringt, welche beim Scoring relevant ist, und Letzteres die Anzahl Fenster oder maximal möglicher Frequenzen erhöht.

        Diese Betrachtungen zeigen, dass noch einige Experimente möglich sind, bevor das Konzept, die von SHAZAM inspirierte Spektralanalyse auf  Proteinsequenzen anzuwenden, als ungeeignet abzulehnen wäre. Die Identifikation einzelner Proteine funktioniert sehr gut, was allerdings bisher nur mit vollständigen Suchsequenzen getestet wurde. Das Erkennen von funktioneller Ähnlichkeit ist hingegen noch schwach. Doch wird ein Weg gefunden, besonders Letzteres zu verbessern, so bietet der Algorithmus eine ganz neue Alternative für die sequenzbasierte Verwandtschaftsanalyse.
    % subsection ausblick (end)
% section diskussion (end)
